from torch import optim
import torch
from torch.cpu import is_available
from tqdm import tqdm
# from tqdm.auto import tqdm
# from helper import *
from fastdemark.model import SkipEncoderDecoder, input_noise
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt

from torchvision.utils import make_grid

def pil_to_np_array(pil_image):
    ar = np.array(pil_image)
    if len(ar.shape) == 3:
        ar = ar.transpose(2,0,1)
    else:
        ar = ar[None, ...]
    return ar.astype(np.float32) / 255.

def np_to_torch_array(np_array):
    return torch.from_numpy(np_array)[None, :]

def torch_to_np_array(torch_array):
    return torch_array.detach().cpu().numpy()[0]

def read_image(path, image_size = -1):
    pil_image = Image.open(path)
    return pil_image

def crop_image(image, crop_factor = 64):
    shape = (image.size[0] - image.size[0] % crop_factor, image.size[1] - image.size[1] % crop_factor)
    bbox = [int((image.shape[0] - shape[0])/2), int((image.shape[1] - shape[1])/2), int((image.shape[0] + shape[0])/2), int((image.shape[1] + shape[1])/2)]
    return image.crop(bbox)

def get_image_grid(images, nrow = 3):
    torch_images = [torch.from_numpy(x) for x in images]
    grid = make_grid(torch_images, nrow)
    return grid.numpy()
    
def visualize_sample(*images_np, nrow = 3, size_factor = 10):
    c = max(x.shape[0] for x in images_np)
    images_np = [x if (x.shape[0] == c) else np.concatenate([x, x, x], axis = 0) for x in images_np]
    grid = get_image_grid(images_np, nrow)
    plt.figure(figsize = (len(images_np) + size_factor, 12 + size_factor))
    plt.axis('off')
    plt.imshow(grid.transpose(1, 2, 0))
    plt.show()

def max_dimension_resize(image_pil, mask_pil, max_dim):
    w, h = image_pil.size
    aspect_ratio = w / h
    if w > max_dim:
        h = int((h / w) * max_dim)
        w = max_dim
    elif h > max_dim:
        w = int((w / h) * max_dim)
        h = max_dim
    return image_pil.resize((w, h)), mask_pil.resize((w, h))

def preprocess_images(image_path, mask_path, max_dim):
    image_pil = read_image(image_path).convert('RGB')
    mask_pil = read_image(mask_path).convert('RGB')

    image_pil, mask_pil = max_dimension_resize(image_pil, mask_pil, max_dim)

    image_np = pil_to_np_array(image_pil)
    mask_np = pil_to_np_array(mask_pil)

    print('Visualizing mask overlap...')

    visualize_sample(image_np, mask_np, image_np * mask_np, nrow = 3, size_factor = 10)

    return image_np, mask_np

def get_available_device() -> str:
    device = 'cpu'

    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = 'mps'

    return device

def remove_watermark(image_path, mask_path, max_dim, reg_noise, input_depth, lr, show_step, training_steps, tqdm_length=100):
    DTYPE = torch.FloatTensor
    device = get_available_device()

    image_np, mask_np = preprocess_images(image_path, mask_path, max_dim)

    print('Building the model...')
    generator = SkipEncoderDecoder(
        input_depth,
        num_channels_down = [128] * 5,
        num_channels_up = [128] * 5,
        num_channels_skip = [128] * 5
    ).type(DTYPE).to(device)

    objective = torch.nn.MSELoss().type(DTYPE).to(device)
    optimizer = optim.Adam(generator.parameters(), lr)

    image_var = np_to_torch_array(image_np).type(DTYPE).to(device)
    mask_var = np_to_torch_array(mask_np).type(DTYPE).to(device)

    generator_input = input_noise(input_depth, image_np.shape[1:]).type(DTYPE).to(device)

    generator_input_saved = generator_input.detach().clone()
    noise = generator_input.detach().clone()

    print('\nStarting training...\n')

    progress_bar = tqdm(range(training_steps), desc='Completed', ncols=tqdm_length)

    for step in progress_bar:
        optimizer.zero_grad()
        generator_input = generator_input_saved

        if reg_noise > 0:
            generator_input = generator_input_saved + (noise.normal_() * reg_noise)

        output = generator(generator_input)

        loss = objective(output * mask_var, image_var * mask_var)
        loss.backward()

        if step % show_step == 0:
            output_image = torch_to_np_array(output)
            visualize_sample(image_np, output_image, nrow = 2, size_factor = 10)

        progress_bar.set_postfix(Loss = loss.item())

        optimizer.step()

    output_image = torch_to_np_array(output)
    visualize_sample(output_image, nrow = 1, size_factor = 10)

    pil_image = Image.fromarray((output_image.transpose(1, 2, 0) * 255.0).astype('uint8'))

    output_path = image_path.split('/')[-1].split('.')[-2] + '-output.jpg'
    print(f'\nSaving final output image to: "{output_path}"\n')

    pil_image.save(output_path)

def create_dynamic_mask(image_path, watermark_region='bottom_right', watermark_ratio=0.25):
    """
    åŠ¨æ€åˆ›å»ºæ°´å°æ©ç å›¾åƒ
    
    Args:
        image_path: åŸå§‹å›¾åƒè·¯å¾„
        watermark_region: æ°´å°ä½ç½® ('bottom_right', 'bottom_left', 'top_right', 'top_left')
        watermark_ratio: æ°´å°åŒºåŸŸå å›¾åƒçš„æ¯”ä¾‹
    
    Returns:
        mask_path: åˆ›å»ºçš„æ©ç æ–‡ä»¶è·¯å¾„
    """
    # è¯»å–åŸå›¾è·å–å°ºå¯¸
    original_img = Image.open(image_path)
    width, height = original_img.size
    
    print(f"è¾“å…¥å›¾åƒå°ºå¯¸: {width} x {height}")
    
    # åˆ›å»ºç™½è‰²èƒŒæ™¯çš„æ©ç å›¾åƒ
    mask = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(mask)
    
    # è®¡ç®—æ°´å°åŒºåŸŸå¤§å°
    watermark_width = int(width * watermark_ratio)
    watermark_height = int(height * watermark_ratio)
    
    # æ ¹æ®æ°´å°ä½ç½®è®¡ç®—åæ ‡
    if watermark_region == 'bottom_right':
        x1 = width - watermark_width
        y1 = height - watermark_height
        x2 = width
        y2 = height
    elif watermark_region == 'bottom_left':
        x1 = 0
        y1 = height - watermark_height
        x2 = watermark_width
        y2 = height
    elif watermark_region == 'top_right':
        x1 = width - watermark_width
        y1 = 0
        x2 = width
        y2 = watermark_height
    elif watermark_region == 'top_left':
        x1 = 0
        y1 = 0
        x2 = watermark_width
        y2 = watermark_height
    else:
        raise ValueError("watermark_region must be one of: 'bottom_right', 'bottom_left', 'top_right', 'top_left'")
    
    # åœ¨æ°´å°åŒºåŸŸç»˜åˆ¶é»‘è‰²çŸ©å½¢ï¼ˆè¡¨ç¤ºéœ€è¦å»é™¤çš„åŒºåŸŸï¼‰
    draw.rectangle([x1, y1, x2, y2], fill='black')
    
    # ç”Ÿæˆæ©ç æ–‡ä»¶è·¯å¾„
    mask_path = image_path.rsplit('.', 1)[0] + '_mask.png'
    
    # ä¿å­˜æ©ç 
    mask.save(mask_path)
    
    print(f"åŠ¨æ€åˆ›å»ºæ©ç : {mask_path}")
    print(f"æ°´å°åŒºåŸŸ: {watermark_region}, åæ ‡: ({x1}, {y1}) to ({x2}, {y2})")
    print(f"æ°´å°åŒºåŸŸå¤§å°: {watermark_width} x {watermark_height}")
    
    return mask_path

def run_complete_watermark_removal(image_path, watermark_region='bottom_right', watermark_ratio=0.25, 
                                 max_dim=512, training_steps=2000, lr=0.01):
    """
    å®Œæ•´çš„å»æ°´å°æµç¨‹ï¼šæ£€æŸ¥å›¾ç‰‡->åˆ›å»ºmask->è¿è¡Œæ¨¡å‹
    
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        watermark_region: æ°´å°ä½ç½®
        watermark_ratio: æ°´å°åŒºåŸŸæ¯”ä¾‹
        max_dim: å›¾åƒæœ€å¤§ç»´åº¦
        training_steps: è®­ç»ƒæ­¥æ•°
        lr: å­¦ä¹ ç‡
    """
    print("=" * 60)
    print("FastDemark å®Œæ•´å»æ°´å°æµç¨‹")
    print("=" * 60)
    
    # 1. æ£€æŸ¥è¾“å…¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    import os
    if not os.path.exists(image_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥å›¾åƒ {image_path}")
        return
    
    # 2. åŠ¨æ€æ£€æŸ¥å›¾ç‰‡å¤§å°å¹¶åˆ›å»ºmask
    print("æ­¥éª¤ 1: åˆ†æè¾“å…¥å›¾ç‰‡...")
    mask_path = create_dynamic_mask(image_path, watermark_region, watermark_ratio)
    
    # 3. è®¾ç½®æ¨¡å‹å‚æ•°
    print("\næ­¥éª¤ 2: è®¾ç½®æ¨¡å‹å‚æ•°...")
    reg_noise = 0.03
    input_depth = 32
    show_step = min(200, training_steps // 100)  # åŠ¨æ€è°ƒæ•´æ˜¾ç¤ºé—´éš”
    
    print(f"æœ€å¤§ç»´åº¦: {max_dim}")
    print(f"è®­ç»ƒæ­¥æ•°: {training_steps}")
    print(f"å­¦ä¹ ç‡: {lr}")
    print(f"æ˜¾ç¤ºé—´éš”: æ¯ {show_step} æ­¥")
    
    # 4. è¿è¡Œå»æ°´å°æ¨¡å‹
    print("\næ­¥éª¤ 3: å¼€å§‹å»æ°´å°å¤„ç†...")
    print("=" * 60)
    
    try:
        remove_watermark(
            image_path=image_path,
            mask_path=mask_path,
            max_dim=max_dim,
            reg_noise=reg_noise,
            input_depth=input_depth,
            lr=lr,
            show_step=show_step,
            training_steps=training_steps
        )
        
        print("\n" + "=" * 60)
        print("âœ… å»æ°´å°å¤„ç†å®Œæˆï¼")
        output_filename = image_path.split('/')[-1].split('.')[0] + '-output.jpg'
        print(f"ğŸ“ è¾“å‡ºå›¾åƒ: {output_filename}")
        print(f"ğŸ“ æ©ç å›¾åƒ: {mask_path}")
        print("=" * 60)
        
        # æ¸…ç†ä¸´æ—¶æ©ç æ–‡ä»¶
        if os.path.exists(mask_path):
            os.remove(mask_path)
            print(f"ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶æ©ç æ–‡ä»¶: {mask_path}")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import sys
    import os
    
    # é»˜è®¤å‚æ•°
    default_image = "resources/water_input.png"
    
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
    else:
        # å°è¯•ä½¿ç”¨é»˜è®¤å›¾ç‰‡
        current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        image_path = os.path.join(current_dir, default_image)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"ä½¿ç”¨æ–¹æ³•: python -m fastdemark.utils [å›¾ç‰‡è·¯å¾„]")
        print(f"æˆ–è€…å°†å›¾ç‰‡æ”¾åˆ°: {default_image}")
        sys.exit(1)
    
    # è¿è¡Œå®Œæ•´çš„å»æ°´å°æµç¨‹
    run_complete_watermark_removal(
        image_path=image_path,
        watermark_region='bottom_right',  # å³ä¸‹è§’æ°´å°
        watermark_ratio=0.25,            # æ°´å°å 25%
        max_dim=512,                     # æœ€å¤§ç»´åº¦512åƒç´ 
        training_steps=2000,             # è®­ç»ƒ2000æ­¥
        lr=0.01                          # å­¦ä¹ ç‡0.01
    )